# Testing API Locally on Your PC

## âœ… Yes, You Can Test on Your PC!

**The API is designed for server deployment, but works perfectly for local testing.**

**What this means:**
- âœ… Run API on your PC
- âœ… Test with Postman, curl, or browser
- âœ… Same code works on server later
- âœ… Model loads once, can test multiple queries

---

## ğŸš€ Quick Start

### 1. Install API Dependencies

```powershell
pip install -r api/requirements.txt
```

### 2. Run API Server

```powershell
cd api
python app.py
```

Or from project root:
```powershell
python -m uvicorn api.app:app --host 0.0.0.0 --port 8000
```

**You'll see:**
```
INFO:     Started server process
INFO:     Waiting for application startup.
âœ… Search service initialized
âœ… RAG service initialized (model will load on first query)
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8000
```

### 3. Test in Browser

Open: `http://localhost:8000/api/health`

Should show:
```json
{
  "status": "healthy",
  "timestamp": "2024-01-01T12:00:00",
  "search_system": "ready",
  "rag_system": "lazy loading"
}
```

### 4. Test Search (No LLM Needed)

**Using curl:**
```powershell
curl -X POST http://localhost:8000/api/search `
  -H "Content-Type: application/json" `
  -d '{\"query\": \"×¤× ×™×•×ª ×××•×¨ ×’×œ×™×œ×™\", \"top_k\": 10}'
```

**Using PowerShell:**
```powershell
$body = @{
    query = "×¤× ×™×•×ª ×××•×¨ ×’×œ×™×œ×™"
    top_k = 10
} | ConvertTo-Json

Invoke-RestMethod -Uri "http://localhost:8000/api/search" `
  -Method POST `
  -ContentType "application/json" `
  -Body $body
```

**This works immediately** - no model loading needed!

### 5. Test RAG (Retrieval Only - Fast)

```powershell
$body = @{
    query = "×›××” ×¤× ×™×•×ª ×™×© ××™× ×™×‘ ×œ×™×‘×•×‘×™×¥?"
    use_llm = $false
    top_k = 20
} | ConvertTo-Json

Invoke-RestMethod -Uri "http://localhost:8000/api/rag/query" `
  -Method POST `
  -ContentType "application/json" `
  -Body $body
```

**This also works immediately** - returns retrieval only (no LLM).

### 6. Test Full RAG (With LLM - Slow First Time)

```powershell
$body = @{
    query = "×›××” ×¤× ×™×•×ª ×™×© ××™× ×™×‘ ×œ×™×‘×•×‘×™×¥?"
    use_llm = $true
    top_k = 20
} | ConvertTo-Json

Invoke-RestMethod -Uri "http://localhost:8000/api/rag/query" `
  -Method POST `
  -ContentType "application/json" `
  -Body $body
```

**First query:** Takes 2-5 minutes (loads model)  
**Subsequent queries:** 5-15 seconds (model cached)

---

## ğŸ”„ Local vs Server

**Local Testing (Your PC):**
- âœ… Same code
- âœ… Same functionality
- âœ… Model loads once (like server)
- âœ… Can test everything
- âš ï¸ Only you can access (localhost)

**Server Deployment:**
- âœ… Multiple users can access
- âœ… Runs 24/7
- âœ… Internal network access
- âœ… Production ready

**The code is the same!** Just deploy to server when ready.

---

## ğŸ“ Testing Checklist

- [ ] API server starts
- [ ] Health check works
- [ ] Search endpoint works (no LLM)
- [ ] RAG endpoint works with `use_llm=false`
- [ ] RAG endpoint works with `use_llm=true` (after model loads)
- [ ] Error handling works
- [ ] Hebrew text displays correctly

---

## ğŸ¯ Next: Build Frontend

Once API works, build a simple web interface:
- HTML + JavaScript
- Connects to your local API
- Can deploy to server later

